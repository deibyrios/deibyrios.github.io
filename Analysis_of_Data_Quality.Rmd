---
keep_md: yes
pagetitle: Analysis of Data Quality
---
```{r, include=FALSE}
knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE, 
                      cache = TRUE)
```

## Analysis of Data Quality
#### (includes data cleaning process)
  
  
### Remodeling of existing and construction of new buildings   
  
As mentioned in the [Description of Data](Description_of_Data.html), the dataset we were able to get, shows the details for every building permit filed with the Department of Buildings, from 1990 to date. This dataset is a list of building permits filed for a particular day and associated data and contains building permits for both new buildings and alterations / remodeling.

After downloading the original dataset (1.4GB, 3,341,659 observations),read it, take a look at it and inspected variables/column names:

```{r}
library(tidyverse)
permits <- read.csv("data/DOB_Permit_Issuance.csv")
#head(permits)
colnames(permits) #print variables / column names
```
<br>

We were able to find a Data Dictionary containing field codes and descriptions of the data sets, which can be downloaded [here](https://data.cityofnewyork.us/api/views/ipu4-2q9a/files/87608d5b-1986-4a21-a8a5-7a38e65f9993?download=true&filename=DD_DOB_Permit_Issuance_2018-03-07.xlsx "Data Dictionary for building permits").

This is a brief description of the variables of our interest:

* __BOROUGH__: The name of the NYC borough
* __House__: The house number for the building
* __Street Name__: The street name (combined with house number completes the address)
* __Zip Code__:	ZIP Code for the building's address
* __Job Type__:	Type of job to be performed.
* __Block__: Tax Block number of the location (assigned by by the Department of Finance)
* __Lot__: Tax Lot number of the location (assigned by by the Department of Finance)
* __Bldg Type__: Legal occupancy classification
* __Work Type__: The specific type of work covered by the permit.
* __Filing Date__: The date the permit application was filed with DOB.
* __Owner's Business Type__: The type of entity that owns the building.

Now we proceed to filter Manhattan Zip codes that are within the area of influence of phase1 and phase 2 of the 2nd Ave Line project (10065, 10021, 10075, 10028, 10128, 10029, 10035) and selected the columns of our interest:

```{r}
#filter Manahattan zip codes of interest:
permits_upper_east <- filter(permits, BOROUGH=="MANHATTAN" & Zip.Code %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035))

#Select relevant columns of our interest:
permits_upper_east <- select(permits_upper_east, House..,Street.Name,Job.Type,Block,Lot,Zip.Code,
                    Bldg.Type,Work.Type,Filing.Date,Owner.s.Business.Type)
#head(permits_upper_east)
#write.table(permits_upper_east, file="DOB_Permit_Issuance_filtered.csv",sep=",",row.names=F)
```

After filtering and selecting variables of our interest, now we look for missing data using extracat::visna():

```{r fig.height=5, fig.width=8}
#install.packages('extracat')
library(extracat)
visna(permits_upper_east)
```

As we can see in the graph above, the quality of the data is very good, with just very few rows missing the Building Type column.

The variables "Block" and "Lot" are of our special interest as those were the main variables used four our main Exploratory Data Analysis as we describe later.
    
       
### Real Estate Sales

In the real estate data, we are able to find all of the sales transactions in New York City since 2003. Because the relevancy of the new subway line and the size of the real estate dataset, we've narrowed the dataset down from 2014 to early 2018, which is a few years right before the Q line had opened to today, and to the surrounding zip codes near the phase 1 Q line. This dataset also includes different types of real estate assets, such as a commercial property and apartment units. As these two assets are not comparable, we've narrowed it down to apartment units, which is where tax class is 2. 

We know that price is likely the biggest indicator to the effects of the Q line on the real estate market, we begin by looking at a boxplot of all of the prices in zip codes 10065,10021, 10075, 10128, 10028 ,10029. As shown below, we can see that prices are highly skewed and have many outliers.

```{r}
library("readxl")
library(reshape)
#install.packages('RSQLite')
library("RSQLite")
```

Importing files

```{r fig.height=9, fig.width=17}

data_ues_1718  <- read.csv(file="data/all_ues_sales_geocode_2017-2018.csv", header=TRUE, sep=",")
boxplot(data_ues_1718$SALE.PRICE)

#note, this is for 17/18 data only
```
In the boxplot above, I've shown a sample of 2017-2018 data with tax class 2 because the original dataset is too big. However, the rest of 2014-2016 have similar trends in outliers. 

When we went through the datasets, we could see many real estate transactions at price 0 or above 10s of  millions! We believe that some properties were sold at a low price as a transaction between family members, and that there are actually relatively few numbers of properties sold above five millions. Therefore, we've narrowed down to looking at properties between 100K and 5M. We do this for both the datasets from NYC DoF and the Baruch dataset. 


```{r}
# source: NYC DoF
data_ues_1718  <- read.csv(file="data/all_ues_sales_geocode_2017-2018.csv", header=TRUE, sep=",")
colnames(data_ues_1718)[colnames(data_ues_1718) == "SALE.PRICE"] <- 'price'
colnames(data_ues_1718)[colnames(data_ues_1718) == "YEAR"] <- 'year'
colnames(data_ues_1718)[colnames(data_ues_1718) == "ZIP.CODE"] <- 'zipcode'
colnames(data_ues_1718)[colnames(data_ues_1718) == "TAX.CLASS.AT.PRESENT"] <- 'TaxClass'
data_ues_1718 <- data_ues_1718[data_ues_1718$price > 100000,]
data_ues_1718 <- data_ues_1718[data_ues_1718$price < 5000000,]
```


```{r}
#Baruch College
# 
# sqlite<- dbDriver("SQLite")
# realestate <- dbConnect(sqlite,"/Users/sharontsao/Desktop/2003-2016 NYC_geocoded_real_estate_sales/NYC_RealEstate_Sales.sqlite")
# 
# dbListTables(realestate)
# 
# data_all = dbGetQuery(realestate,'select sale_id, year, nbhd, block, lot, address, zip, sale_date, price, long, lat
#                       from yr_2016 where zip in (10065,10021, 10075, 10028 ,10029) 
#                       AND usable = "True" 
#                       AND tax_cls_s = 2
#                       AND price > 100000
#                       AND price < 5000000
#                       
#             UNION
#                       select sale_id, year, nbhd, block, lot, address, zip, sale_date, price, long, lat
#                       from yr_2015 where zip in (10065,10021, 10075, 10028 ,10029) 
#                       AND usable = "True" 
#                       AND tax_cls_s = 2
#                       AND price > 100000
#                       AND price < 5000000
# 
#             UNION
# 
#                       select sale_id, year, nbhd, block, lot, address, zip, sale_date, price, long, lat
#                       from yr_2014 where zip in (10065,10021, 10075, 10028 ,10029) 
#                       AND usable = "True" 
#                       AND tax_cls_s = 2
#                       AND price > 100000
#                       AND price < 5000000')
```

With the Baruch dataset above, I've only shown the code and the output because the dataset is also too big to import to github.
<br>
The above steps lay the groudwork of the dataset of focus. These are a brief description of the columns we're using: 
<br>
- **Tax Class**: The class of the building helps us identify the real estate type (Houses, Apartments, Building) <br>
- **Block**: Block number helps us identify the location of the block <br>
- **Lot**: Lot number helps us identify the location of the lot <br>
- **Zip Code**: Zip code of the real estate property <br>
- **Sale Date**: Date the real estate transaction was closed <br>
- **Sale Price**: Price the buyer paid for <br>
- **Lat/Long**: The Coordinates of the real estate property <br>
         
We're using these variables to help us analyze trends in real estate prices. 

### Property Market Values

As mentioned in the [Description of Data](Description_of_Data.html), we were able to find the property market values from 2018 back to 2008 with 12 datasets in total, **one dataset for each year** except 2008 that contains 2 different datasets the needed to be combined.

We were able to find a Data Dictionary containing field codes and descriptions of the data sets, which can be accessed [here](http://www1.nyc.gov/assets/finance/downloads/tar/tarfieldcodes.pdf "Data Dictionary for property market values").

After downloading and extracting the zip files for all the original datasets we read each dataset, take a look at it, read the corresponding Data Dictionary and inspect variables/column names. The data consists of Access databases so we used RODBC library to read the databases using "odbcConnectAccess('my_Access_Database_to_read.mdb')".

**Note:** The original 12 Access databases have a total size of 4.34Gb, take too long time to be read and can't be uploaded to GitHub, so we included the following commented code just **to document our work**, but we uploaded the smaller data after filtering and selecting our variables of interest. 

```{r}
# library(tidyverse)
# #install.packages('RODBC')
# library(RODBC)
# 
# mdbConnect<-odbcConnectAccess("avroll_19.mdb")
# property <- sqlFetch(mdbConnect,"avroll")
# odbcClose(mdbConnect)
# #head(property)
# #colnames(property) #print variables / column names
# 
# property_upper_east <- property %>% 
#   filter(B==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2018)
# str(property_upper_east) 
# 
# mdbConnect<-odbcConnectAccess("avroll_18.mdb")
# new_property <- sqlFetch(mdbConnect,"avroll")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>% 
#   filter(B==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2017)
# str(new_property_upper_east) 
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# #str(property_upper_east)
# #write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
# 
# mdbConnect<-odbcConnectAccess("avroll_17.mdb")
# new_property <- sqlFetch(mdbConnect,"avroll")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>% 
#   filter(B==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2016)
# str(new_property_upper_east) 
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# #str(property_upper_east)
# #write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
# 
# mdbConnect<-odbcConnectAccess("avroll_16.mdb")
# new_property <- sqlFetch(mdbConnect,"avroll")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>% 
#   filter(B==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2015)
# str(new_property_upper_east) 
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# #str(property_upper_east)
# #write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
# 
# mdbConnect<-odbcConnectAccess("avroll_15.mdb")
# new_property <- sqlFetch(mdbConnect,"avroll")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>% 
#   filter(B==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2014)
# str(new_property_upper_east) 
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# #str(property_upper_east)
# #write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
# 
# mdbConnect<-odbcConnectAccess("avroll_14.mdb")
# new_property <- sqlFetch(mdbConnect,"avroll")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>% 
#   filter(B==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2013)
# str(new_property_upper_east) 
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# #str(property_upper_east)
# #write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
# 
# mdbConnect<-odbcConnectAccess("avroll_13.mdb")
# new_property <- sqlFetch(mdbConnect,"avroll")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>% 
#   filter(B==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2012)
# str(new_property_upper_east) 
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# #str(property_upper_east)
# #write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
# 
# mdbConnect<-odbcConnectAccess("avroll_12.mdb")
# new_property <- sqlFetch(mdbConnect,"avroll")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>% 
#   filter(B==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2011)
# str(new_property_upper_east) 
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# #str(property_upper_east)
# #write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
# 
# mdbConnect<-odbcConnectAccess("avroll_11.mdb")
# new_property <- sqlFetch(mdbConnect,"avroll")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>% 
#   filter(B==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2010)
# str(new_property_upper_east) 
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# #str(property_upper_east)
# #write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
# 
# mdbConnect<-odbcConnectAccess("avroll_10.mdb")
# new_property <- sqlFetch(mdbConnect,"avroll")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>% 
#   filter(B==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2009)
# str(new_property_upper_east) 
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# #str(property_upper_east)
# #write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
# 
# mdbConnect<-odbcConnectAccess("avroll_09_class 1.mdb")
# new_property <- sqlFetch(mdbConnect,"tc1")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>%
#   mutate(FULLVAL = NEW_FV_T) %>%
#   filter(BORO==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2008)
# str(new_property_upper_east)
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# #str(property_upper_east)
# #write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
# 
# mdbConnect<-odbcConnectAccess("avroll_09_class 2,3,4.mdb")
# new_property <- sqlFetch(mdbConnect,"tc234")
# odbcClose(mdbConnect)
# #head(new_property)
# #colnames(new_property) #print variables / column names
# 
# new_property_upper_east <- new_property %>%
#   mutate(FULLVAL = NEW_FV_T) %>%
#   filter(BORO==1 & ZIP %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>% select(BLOCK,LOT,BLDGCL,FULLVAL) %>%
#     mutate(Year = 2008)
# str(new_property_upper_east)
# 
# property_upper_east <- rbind.data.frame(new_property_upper_east, property_upper_east)
# str(property_upper_east)
# #Next, we write a new file 'property_upper_east.csv' in the working directory, for future use whenever we need to read the data again, because reading the original files takes too long time:
# write.table(property_upper_east, file="property_upper_east.csv",sep=",",row.names=F)
```

This is a brief description of the variables of our interest utilized in the code above:

* BORO: The name of the NYC borough
* ZIP:	ZIP Code for the property's address
* BLOCK: Tax Block number of the location (assigned by by the Department of Finance)
* LOT: Tax Lot number of the location (assigned by by the Department of Finance)
* BLDGCL: 2 digits building class code (see codes [here](http://www1.nyc.gov/assets/finance/jump/hlpbldgcode.html "Building class Codes"))
* FULLVAL/NEW_FV_T: Total next market value estimated for next fiscal year  

After filtering zip codes in the area of influence of phase1 and phase 2 of the 2nd Ave Line project (10065, 10021, 10075, 10028, 10128, 10029, 10035) and selecting variables of our interest, we looked for missing data using extracat::visna(), but we got 'Error in visna(property_upper_east) : No NA's in the data', so we used mi::missing_data.frame() instead, just to double check:

```{r}
#library(tidyverse)
property_upper_east <- read.csv("data/property_upper_east.csv") #already filtered and selected data
#install.packages('extracat')
library(mi)
show(missing_data.frame(property_upper_east))
```

No we confirmed that there are no NA's in the data so the quality of the data is very good.

Again, the variables "Block" and "Lot" are of our special interest as those were the main variables used four our main Exploratory Data Analysis as we describe later.
    
     
### Property Assessed Values

As mentioned in the [Description of Data](Description_of_Data.html), we were able to find property "Assessed Values" from 2003 to 2017 in the "Primary Land Use Tax Lot Output" (PLUTO) dataset, developed by the New York City Department of City Planning's (DCP). 

We were able to find a Data Dictionary containing field codes and descriptions of the data sets, which can be accessed [here](http://www1.nyc.gov/assets/planning/download/pdf/data-maps/open-data/pluto_datadictionary.pdf "Data Dictionary for property assessed values").

After downloading and extracting the zip files for the original datasets we read each dataset, take a look at it, read the corresponding Data Dictionary and inspect variables/column names. The datasets are shapefiles so we used the "foreign" library to read the data files of the shapefiles using "read.dbf('my_shapefile_to_read.dbf')".

**Note:** The original 15 datasets are an extensive land use and geographic data at the tax lot level, containing more than seventy fields derived from data maintained by different city agencies so they have a large size, take too long time to be read and can't be uploaded to GitHub, so we included the following commented code just **to document our work**, but we uploaded the smaller data after filtering and selecting our variables of interest.

```{r}
# library(tidyverse)
# library(foreign) #used to read .dbf files
# 
# PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/mn_mappluto_17v1_1/MNMapPLUTO.dbf")
# #head(PLUTO)
# 
# PLUTO <- PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2017)
# str(PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_16/MNMapPLUTO.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2016)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_15/MNMapPLUTO.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2015)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_14/MNMapPLUTO.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2014)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_13/MNMapPLUTO.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2013)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_12/MNMapPLUTO.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2012)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_11/MNMapPLUTO.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2011)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_10/MNMapPLUTO.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2010)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_09/MNMapPLUTO.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2009)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_08/MNMapPLUTO.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2008)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_07/mnmappluto.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2007)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_06/mnmappluto.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(Block,Lot,BldgClass,AssessTot,XCoord,YCoord) %>%
#   mutate(Year = 2006)
# str(New_PLUTO)
# 
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_05/mnmappluto.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZIPCODE %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(BLOCK,LOT,BLDGCLASS,ASSESSTOT,XCOORD,YCOORD) %>%
#   mutate(Year = 2005)
# str(New_PLUTO)
# 
# colnames(New_PLUTO) <- c("Block","Lot","BldgClass","AssessTot","XCoord","YCoord","Year")
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_04/mnmappluto.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(ZIPCODE %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(BLOCK,LOT,BLDGCLASS,ASSESSTOTA,XCOORD,YCOORD) %>%
#   mutate(Year = 2004)
# str(New_PLUTO)
# 
# colnames(New_PLUTO) <- c("Block","Lot","BldgClass","AssessTot","XCoord","YCoord","Year")
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# 
# New_PLUTO <- read.dbf("c:/Users/yenny/Downloads/Columbia/Exploratory Data/final project/Market Values 2009-2019/Mappluto/Manhattan_03/mnmappluto.dbf")
# #head(New_PLUTO)
# 
# New_PLUTO  <- New_PLUTO %>%
#   filter(zipCode %in% c(10065, 10021, 10075, 10028, 10128, 10029, 10035)) %>%
#   select(block,lot,bldgClass,assessTotl,xCoord,yCoord) %>%
#   mutate(Year = 2003)
# str(New_PLUTO)
# 
# colnames(New_PLUTO) <- c("Block","Lot","BldgClass","AssessTot","XCoord","YCoord","Year")
# PLUTO <- rbind.data.frame(New_PLUTO, PLUTO)
# str(PLUTO)
# 
# #Next, we write a new file 'property_upper_east.csv' in the working directory, for future use whenever we need to read the data again, because reading the original files takes too long time:
# write.table(PLUTO, file="PLUTO_upper_east.csv",sep=",",row.names=F)
```

This is a brief description of the variables of our interest utilized in the code above:

* ZipCode: ZIP Code for the property's address
* Block: Tax Block number of the location (assigned by by the Department of Finance)
* Lot: Tax Lot number of the location (assigned by by the Department of Finance)
* BldgClass: 2 digits building class code (see codes [here](http://www1.nyc.gov/assets/finance/jump/hlpbldgcode.html "Building class Codes"))
* AssessTot: Total Property Assessed Value  

After filtering zip codes in the area of influence of phase1 and phase 2 of the 2nd Ave Line project (10065, 10021, 10075, 10028, 10128, 10029, 10035) and selecting variables of our interest, we looked for missing data using extracat::visna(), but we got 'Error in visna(property_upper_east) : No NA's in the data', so we used mi::missing_data.frame() instead, just to double check:

```{r}
#library(tidyverse)
property_upper_east <- read.csv("data/PLUTO_upper_east.csv") #already filtered and selected data
#install.packages('extracat')
library(mi)
show(missing_data.frame(property_upper_east))
```

No we confirmed that there are no NA's in the data so the quality of the data is very good.

Same than for the analysis for building permits and the analysis for property market values, the variables "Block" and "Lot" are of our special interest as those were the main variables used four our main Exploratory Data Analysis as we describe later.
          
      
### Other Datasets?
Add other datasets here if any.
_Provide a detailed, well-organized description of data quality, including textual description, graphs, and code_
    